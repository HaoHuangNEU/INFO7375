# INFO7375
go to https://github.com/ollama/ollama and download for windows version
![image](https://github.com/HaoHuangNEU/INFO7375/assets/113487970/10e1d3b5-cd3f-4574-8bcf-a8ee9021beeb)

After downloading use cmd to run Llama3 with command **ollama run llama3**

![image](https://github.com/HaoHuangNEU/INFO7375/assets/113487970/3ce4d07c-1108-4736-adc2-c0a49f6b2160)
input curl command: **curl https://google.com**
The result is:
![image](https://github.com/HaoHuangNEU/INFO7375/assets/113487970/1d8ea91f-9131-4e0d-8c4f-dfb1dc207af9)

The ollama has different LLM model, so we can use **ollama run phi3** to run a different LLM and the result is: 
![image](https://github.com/HaoHuangNEU/INFO7375/assets/113487970/a41e0fc1-6b76-4836-bd14-643e8cfc4541)


Both LLM explains what does curl command do except Llama3 outputs the result of the command while phi3 doesn't.


youtube video link: https://www.youtube.com/watch?v=ELOX_rGgJ_I
